{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Library Book Recommendation System**\n",
    "---\n",
    "Authors: [Monicah Iwagit](https://github.com/Okodoimonicah), [Bradley Azegele](https://github.com/Azegele), [Emmanuel Kipkorir](), [Belinda Nyamai](), [Femi Kamau](https://github.com/ctrl-Karugu), and [Dennis Kimiri]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Business Understanding\n",
    "\n",
    "### 1.1 Problem Statement\n",
    ">The tremendous growth and usage of information has led to information overloading where users find it difficult to locate the right information at a specified time. Although there are previous studies conducted on library recommender systems, the datasets used were small compared to the dataset we intend to use hence minimal area coverage. Recommending the right library books is a challenge due to the variety of genres available and the huge collection of books provided. A user finds it difficult to select the most appropriate book that will suit their academic needs, this process consumes a lot of time that the user would have used to sharpen on their desired skills. Additionally, many books in the library are rarely utilized which results in a waste of library resources. Having a personalized recommendation system seeks to predict the preference based on the userâ€™s interest, behavior and information. The application of recommender systems in a library set up solves the problem of difficulty in choosing books and improves utilization rate of library resources. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Understanding\n",
    "> The goal of the Data Understanding phase is to provide a solid foundation for the subsequent steps, including data preparation, exploratory data analysis, model development, and evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from string import punctuation\n",
    "import isbnlib\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Miscellaneous\n",
    "import warnings\n",
    "\n",
    "# Settings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Collect Initial Data\n",
    "> The aim of this section is to acquire the necessary data and load it into the notebook.\n",
    "\n",
    "The data used in this project was extracted from 2 different sources:\n",
    ">   1. The first was source was from Cai-Nicolas Ziegler in a 4-week crawl (August-September [2004]) in the University of Freiburg, Germany. This can be found [here](http://www2.informatik.uni-freiburg.de/~cziegler/BX/). The data obtained are 3 datasets with information on [users](./data/BX-Users.csv), [ratings](./data/BX-Book-Ratings.csv) and [books](./data/BX-Books.csv) from a library.\n",
    ">\n",
    ">   2. The second set of data was sourced from the [Google Books API](https://developers.google.com/books). This data was obtained by using ISBNs in the books dataset from the first source. The python script used to extract the data can be found [here](./make_dataset.py). This data was then stored in csv format and can be found [here](./data/api-data.csv)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Source 1)\n",
    "ratings = pd.read_csv(\"data/BX-Book-Ratings.csv\", sep=\";\", on_bad_lines=\"skip\", encoding=\"iso-8859-1\")\n",
    "books = pd.read_csv(\"data/BX-Books.csv\", sep=\";\", on_bad_lines=\"skip\", encoding=\"iso-8859-1\")\n",
    "users = pd.read_csv(\"data/BX-Users.csv\", sep=\";\", on_bad_lines=\"skip\", encoding=\"iso-8859-1\")\n",
    "\n",
    "# (Source 2)\n",
    "books_extra = pd.read_csv(\"data/api-books.csv\", dtype={\"join_isbn_10\": str})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Describe Data\n",
    "> The aim of this section is to examine the data and document its surface properties.\n",
    "\n",
    "*(Needs a initial description of the surface properties that we shall be looking at in this section)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class to describe the data \n",
    "class DescribeData:\n",
    "    \"\"\"This class is used to describe the data in a DataFrame.\"\"\"\n",
    "    \n",
    "    def __init__(self, df) -> None:\n",
    "        \n",
    "        # Get the DataFrame\n",
    "        self.df = df\n",
    "        \n",
    "        # Get the datatypes of the columns in the DataFrame\n",
    "        self.datatypes = df.dtypes\n",
    "         \n",
    "        # Get the shape of the DataFrame\n",
    "        self.shape = f\"The shape of the DataFrame is {df.shape}\\n\\nRecords: {df.shape[0]}\\nColumns: {df.shape[1]}\"\n",
    "        \n",
    "        # Get the number of missing values in each column\n",
    "        self.missing = f\"There are a total of {df.isnull().sum().values.sum()} missing values in the DataFrame.\\n\\n{df.isnull().sum()}\"\n",
    "        \n",
    "        # Get the number of duplicate rows\n",
    "        self.duplicates = f\"There are {df.duplicated().sum()} duplicated records in the DataFrame.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 `ratings`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the 'DescribeData' class for the 'ratings' DataFrame\n",
    "rt = DescribeData(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>276725</td>\n",
       "      <td>034545104X</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>276726</td>\n",
       "      <td>0155061224</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>276727</td>\n",
       "      <td>0446520802</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>276729</td>\n",
       "      <td>052165615X</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>276729</td>\n",
       "      <td>0521795028</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User-ID        ISBN  Book-Rating\n",
       "0   276725  034545104X            0\n",
       "1   276726  0155061224            5\n",
       "2   276727  0446520802            0\n",
       "3   276729  052165615X            3\n",
       "4   276729  0521795028            6"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the 'ratings' DataFrame\n",
    "rt.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1149780 entries, 0 to 1149779\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count    Dtype \n",
      "---  ------       --------------    ----- \n",
      " 0   User-ID      1149780 non-null  int64 \n",
      " 1   ISBN         1149780 non-null  object\n",
      " 2   Book-Rating  1149780 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 26.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Inspect the information about the DataFrame\n",
    "rt.df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the DataFrame is (1149780, 3)\n",
      "\n",
      "Records: 1149780\n",
      "Columns: 3\n"
     ]
    }
   ],
   "source": [
    "# Inspect the shape of the DataFrame\n",
    "print(rt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-ID         int64\n",
      "ISBN           object\n",
      "Book-Rating     int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Inspect the datatypes of the columns in the DataFrame\n",
    "print(rt.datatypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Book-Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.149780e+06</td>\n",
       "      <td>1.149780e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.403864e+05</td>\n",
       "      <td>2.866950e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.056228e+04</td>\n",
       "      <td>3.854184e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.034500e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.410100e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.110280e+05</td>\n",
       "      <td>7.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.788540e+05</td>\n",
       "      <td>1.000000e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            User-ID   Book-Rating\n",
       "count  1.149780e+06  1.149780e+06\n",
       "mean   1.403864e+05  2.866950e+00\n",
       "std    8.056228e+04  3.854184e+00\n",
       "min    2.000000e+00  0.000000e+00\n",
       "25%    7.034500e+04  0.000000e+00\n",
       "50%    1.410100e+05  0.000000e+00\n",
       "75%    2.110280e+05  7.000000e+00\n",
       "max    2.788540e+05  1.000000e+01"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the summary statistics of the DataFrame\n",
    "rt.df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of 0 missing values in the DataFrame.\n",
      "\n",
      "User-ID        0\n",
      "ISBN           0\n",
      "Book-Rating    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Inspect the number of missing values in each column\n",
    "print(rt.missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 duplicated records in the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "# Inspect the duplicates in the DataFrame\n",
    "print(rt.duplicates)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**Ratings Dataset**](./data/BX-Book-Ratings.csv)\n",
    "\n",
    ">* Spans **3** columns and **1,149,780** rows.\n",
    "\n",
    ">* Contains **2** unique datatypes: \n",
    ">    * **int64**\n",
    ">    * **object**\n",
    "\n",
    ">* No missing values\n",
    "\n",
    ">* No duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 `books` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the 'DescribeData' class for the 'books' DataFrame\n",
    "bk = DescribeData(books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Image-URL-S</th>\n",
       "      <th>Image-URL-M</th>\n",
       "      <th>Image-URL-L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0195153448</td>\n",
       "      <td>Classical Mythology</td>\n",
       "      <td>Mark P. O. Morford</td>\n",
       "      <td>2002</td>\n",
       "      <td>Oxford University Press</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0195153448.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002005018</td>\n",
       "      <td>Clara Callan</td>\n",
       "      <td>Richard Bruce Wright</td>\n",
       "      <td>2001</td>\n",
       "      <td>HarperFlamingo Canada</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0002005018.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0060973129</td>\n",
       "      <td>Decision in Normandy</td>\n",
       "      <td>Carlo D'Este</td>\n",
       "      <td>1991</td>\n",
       "      <td>HarperPerennial</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0060973129.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0374157065</td>\n",
       "      <td>Flu: The Story of the Great Influenza Pandemic...</td>\n",
       "      <td>Gina Bari Kolata</td>\n",
       "      <td>1999</td>\n",
       "      <td>Farrar Straus Giroux</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0374157065.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0393045218</td>\n",
       "      <td>The Mummies of Urumchi</td>\n",
       "      <td>E. J. W. Barber</td>\n",
       "      <td>1999</td>\n",
       "      <td>W. W. Norton &amp;amp; Company</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "      <td>http://images.amazon.com/images/P/0393045218.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ISBN                                         Book-Title  \\\n",
       "0  0195153448                                Classical Mythology   \n",
       "1  0002005018                                       Clara Callan   \n",
       "2  0060973129                               Decision in Normandy   \n",
       "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
       "4  0393045218                             The Mummies of Urumchi   \n",
       "\n",
       "            Book-Author Year-Of-Publication                   Publisher  \\\n",
       "0    Mark P. O. Morford                2002     Oxford University Press   \n",
       "1  Richard Bruce Wright                2001       HarperFlamingo Canada   \n",
       "2          Carlo D'Este                1991             HarperPerennial   \n",
       "3      Gina Bari Kolata                1999        Farrar Straus Giroux   \n",
       "4       E. J. W. Barber                1999  W. W. Norton &amp; Company   \n",
       "\n",
       "                                         Image-URL-S  \\\n",
       "0  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0060973129.0...   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   \n",
       "4  http://images.amazon.com/images/P/0393045218.0...   \n",
       "\n",
       "                                         Image-URL-M  \\\n",
       "0  http://images.amazon.com/images/P/0195153448.0...   \n",
       "1  http://images.amazon.com/images/P/0002005018.0...   \n",
       "2  http://images.amazon.com/images/P/0060973129.0...   \n",
       "3  http://images.amazon.com/images/P/0374157065.0...   \n",
       "4  http://images.amazon.com/images/P/0393045218.0...   \n",
       "\n",
       "                                         Image-URL-L  \n",
       "0  http://images.amazon.com/images/P/0195153448.0...  \n",
       "1  http://images.amazon.com/images/P/0002005018.0...  \n",
       "2  http://images.amazon.com/images/P/0060973129.0...  \n",
       "3  http://images.amazon.com/images/P/0374157065.0...  \n",
       "4  http://images.amazon.com/images/P/0393045218.0...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the 'books' DataFrame\n",
    "bk.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 271360 entries, 0 to 271359\n",
      "Data columns (total 8 columns):\n",
      " #   Column               Non-Null Count   Dtype \n",
      "---  ------               --------------   ----- \n",
      " 0   ISBN                 271360 non-null  object\n",
      " 1   Book-Title           271360 non-null  object\n",
      " 2   Book-Author          271359 non-null  object\n",
      " 3   Year-Of-Publication  271360 non-null  object\n",
      " 4   Publisher            271358 non-null  object\n",
      " 5   Image-URL-S          271360 non-null  object\n",
      " 6   Image-URL-M          271360 non-null  object\n",
      " 7   Image-URL-L          271357 non-null  object\n",
      "dtypes: object(8)\n",
      "memory usage: 16.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Inspect the information about the DataFrame\n",
    "bk.df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the DataFrame is (271360, 8)\n",
      "\n",
      "Records: 271360\n",
      "Columns: 8\n"
     ]
    }
   ],
   "source": [
    "# Inspect the shape of the DataFrame\n",
    "print(bk.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISBN                   object\n",
      "Book-Title             object\n",
      "Book-Author            object\n",
      "Year-Of-Publication    object\n",
      "Publisher              object\n",
      "Image-URL-S            object\n",
      "Image-URL-M            object\n",
      "Image-URL-L            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Inspect the datatypes of the columns in the DataFrame\n",
    "print(bk.datatypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of 6 missing values in the DataFrame.\n",
      "\n",
      "ISBN                   0\n",
      "Book-Title             0\n",
      "Book-Author            1\n",
      "Year-Of-Publication    0\n",
      "Publisher              2\n",
      "Image-URL-S            0\n",
      "Image-URL-M            0\n",
      "Image-URL-L            3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Inspect the missing values in the DataFrame\n",
    "print(bk.missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 duplicated records in the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "# Inspect the duplicates in the DataFrame\n",
    "print(bk.duplicates)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**Books Dataset**](./data/BX-Books.csv)\n",
    "\n",
    ">* Spans **8** columns and **271,360** rows.\n",
    "\n",
    ">* Contains 1 unique datatype: \n",
    ">   * **object**\n",
    "\n",
    ">* **6** missing values:\n",
    ">   * Book-Author: **1** \n",
    ">   * Publisher: **2**\n",
    ">   * Image-URL-L: **3**\n",
    "\n",
    ">* No duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.3 `users` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the 'DescribeData' class for the 'users' DataFrame\n",
    "ur = DescribeData(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Location</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>nyc, new york, usa</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>stockton, california, usa</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>moscow, yukon territory, russia</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>porto, v.n.gaia, portugal</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>farnborough, hants, united kingdom</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User-ID                            Location   Age\n",
       "0        1                  nyc, new york, usa   NaN\n",
       "1        2           stockton, california, usa  18.0\n",
       "2        3     moscow, yukon territory, russia   NaN\n",
       "3        4           porto, v.n.gaia, portugal  17.0\n",
       "4        5  farnborough, hants, united kingdom   NaN"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the 'users' DataFrame\n",
    "ur.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 278858 entries, 0 to 278857\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count   Dtype  \n",
      "---  ------    --------------   -----  \n",
      " 0   User-ID   278858 non-null  int64  \n",
      " 1   Location  278858 non-null  object \n",
      " 2   Age       168096 non-null  float64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 6.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Inspect the information about the DataFrame\n",
    "ur.df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the DataFrame is (278858, 3)\n",
      "\n",
      "Records: 278858\n",
      "Columns: 3\n"
     ]
    }
   ],
   "source": [
    "# Inspect the shape of the DataFrame\n",
    "print(ur.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-ID       int64\n",
      "Location     object\n",
      "Age         float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Inspect the datatypes of the columns in the DataFrame\n",
    "print(ur.datatypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User-ID</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>278858.00000</td>\n",
       "      <td>168096.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>139429.50000</td>\n",
       "      <td>34.751434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>80499.51502</td>\n",
       "      <td>14.428097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>69715.25000</td>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>139429.50000</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>209143.75000</td>\n",
       "      <td>44.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>278858.00000</td>\n",
       "      <td>244.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            User-ID            Age\n",
       "count  278858.00000  168096.000000\n",
       "mean   139429.50000      34.751434\n",
       "std     80499.51502      14.428097\n",
       "min         1.00000       0.000000\n",
       "25%     69715.25000      24.000000\n",
       "50%    139429.50000      32.000000\n",
       "75%    209143.75000      44.000000\n",
       "max    278858.00000     244.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the summary statistics of the DataFrame\n",
    "ur.df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of 110762 missing values in the DataFrame.\n",
      "\n",
      "User-ID          0\n",
      "Location         0\n",
      "Age         110762\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Inspect the missing values in the DataFrame\n",
    "print(ur.missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 duplicated records in the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "# Inspect the duplicates in the DataFrame\n",
    "print(ur.duplicates)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**Users Dataset**](./data/BX-Users.csv)\n",
    "\n",
    ">* Spans **3** columns and **278,858** rows.\n",
    "\n",
    ">* Contains **3** unique datatypes:\n",
    ">   * **int64**\n",
    ">   * **float64**\n",
    ">   * **object**\n",
    "\n",
    ">* **110,762** missing values:\n",
    ">   * Age: **110,762**\n",
    "\n",
    ">* No duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.4 `books_extra`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the 'DescribeData' class for the 'books_extra' DataFrame\n",
    "bk_extra = DescribeData(books_extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>authors</th>\n",
       "      <th>published_date</th>\n",
       "      <th>description</th>\n",
       "      <th>isbn_10</th>\n",
       "      <th>isbn_13</th>\n",
       "      <th>page_count</th>\n",
       "      <th>categories</th>\n",
       "      <th>maturity_rating</th>\n",
       "      <th>language</th>\n",
       "      <th>join_isbn_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['Mark P. O. Morford', 'Robert J. Lenardon']</td>\n",
       "      <td>2003</td>\n",
       "      <td>Provides an introduction to classical myths pl...</td>\n",
       "      <td>0195153448</td>\n",
       "      <td>9780195153446.0</td>\n",
       "      <td>808.0</td>\n",
       "      <td>['Social Science']</td>\n",
       "      <td>NOT_MATURE</td>\n",
       "      <td>en</td>\n",
       "      <td>0195153448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0002005018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[\"Carlo D'Este\"]</td>\n",
       "      <td>1991</td>\n",
       "      <td>Here, for the first time in paperback, is an o...</td>\n",
       "      <td>IND:30000026059836</td>\n",
       "      <td>NaN</td>\n",
       "      <td>582.0</td>\n",
       "      <td>['1940-1949']</td>\n",
       "      <td>NOT_MATURE</td>\n",
       "      <td>en</td>\n",
       "      <td>0060973129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['Gina Bari Kolata']</td>\n",
       "      <td>1999</td>\n",
       "      <td>Describes the great flu epidemic of 1918, an o...</td>\n",
       "      <td>9780374157067</td>\n",
       "      <td>374157065.0</td>\n",
       "      <td>367.0</td>\n",
       "      <td>['Medical']</td>\n",
       "      <td>NOT_MATURE</td>\n",
       "      <td>en</td>\n",
       "      <td>0374157065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['E. J. W. Barber']</td>\n",
       "      <td>1999</td>\n",
       "      <td>A look at the incredibly well-preserved ancien...</td>\n",
       "      <td>0393045218</td>\n",
       "      <td>9780393045215.0</td>\n",
       "      <td>240.0</td>\n",
       "      <td>['Design']</td>\n",
       "      <td>NOT_MATURE</td>\n",
       "      <td>en</td>\n",
       "      <td>0393045218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        authors published_date  \\\n",
       "0  ['Mark P. O. Morford', 'Robert J. Lenardon']           2003   \n",
       "1                                           NaN            NaN   \n",
       "2                              [\"Carlo D'Este\"]           1991   \n",
       "3                          ['Gina Bari Kolata']           1999   \n",
       "4                           ['E. J. W. Barber']           1999   \n",
       "\n",
       "                                         description             isbn_10  \\\n",
       "0  Provides an introduction to classical myths pl...          0195153448   \n",
       "1                                                NaN                 NaN   \n",
       "2  Here, for the first time in paperback, is an o...  IND:30000026059836   \n",
       "3  Describes the great flu epidemic of 1918, an o...       9780374157067   \n",
       "4  A look at the incredibly well-preserved ancien...          0393045218   \n",
       "\n",
       "           isbn_13  page_count          categories maturity_rating language  \\\n",
       "0  9780195153446.0       808.0  ['Social Science']      NOT_MATURE       en   \n",
       "1              NaN         NaN                 NaN             NaN      NaN   \n",
       "2              NaN       582.0       ['1940-1949']      NOT_MATURE       en   \n",
       "3      374157065.0       367.0         ['Medical']      NOT_MATURE       en   \n",
       "4  9780393045215.0       240.0          ['Design']      NOT_MATURE       en   \n",
       "\n",
       "  join_isbn_10  \n",
       "0   0195153448  \n",
       "1   0002005018  \n",
       "2   0060973129  \n",
       "3   0374157065  \n",
       "4   0393045218  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preview the 'books_extra' DataFrame\n",
    "bk_extra.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 271044 entries, 0 to 271043\n",
      "Data columns (total 10 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   authors          210684 non-null  object \n",
      " 1   published_date   212589 non-null  object \n",
      " 2   description      180298 non-null  object \n",
      " 3   isbn_10          212653 non-null  object \n",
      " 4   isbn_13          179739 non-null  object \n",
      " 5   page_count       211385 non-null  float64\n",
      " 6   categories       199011 non-null  object \n",
      " 7   maturity_rating  212741 non-null  object \n",
      " 8   language         212741 non-null  object \n",
      " 9   join_isbn_10     271044 non-null  object \n",
      "dtypes: float64(1), object(9)\n",
      "memory usage: 20.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Inspect the information about the DataFrame\n",
    "bk_extra.df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the DataFrame is (271044, 10)\n",
      "\n",
      "Records: 271044\n",
      "Columns: 10\n"
     ]
    }
   ],
   "source": [
    "# Inspect the shape of the DataFrame\n",
    "print(bk_extra.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "authors             object\n",
      "published_date      object\n",
      "description         object\n",
      "isbn_10             object\n",
      "isbn_13             object\n",
      "page_count         float64\n",
      "categories          object\n",
      "maturity_rating     object\n",
      "language            object\n",
      "join_isbn_10        object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Inspect the datatypes of the columns in the DataFrame\n",
    "print(bk_extra.datatypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>211385.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>279.534995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>179.001719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>176.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>260.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>356.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3596.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          page_count\n",
       "count  211385.000000\n",
       "mean      279.534995\n",
       "std       179.001719\n",
       "min         0.000000\n",
       "25%       176.000000\n",
       "50%       260.000000\n",
       "75%       356.000000\n",
       "max      3596.000000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the summary statistics of the DataFrame\n",
    "bk_extra.df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are a total of 607555 missing values in the DataFrame.\n",
      "\n",
      "authors            60360\n",
      "published_date     58455\n",
      "description        90746\n",
      "isbn_10            58391\n",
      "isbn_13            91305\n",
      "page_count         59659\n",
      "categories         72033\n",
      "maturity_rating    58303\n",
      "language           58303\n",
      "join_isbn_10           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Inspect the missing values in the DataFrame\n",
    "print(bk_extra.missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 duplicated records in the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "# Inspect the duplicates in the DataFrame\n",
    "print(bk_extra.duplicates)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[**Books (Extra) Dataset**](./data/api-books.csv)\n",
    "\n",
    ">* Spans **10** columns and **271,044** rows.\n",
    "\n",
    ">* Contains **2** unique datatypes:\n",
    ">   * **float64**\n",
    ">   * **object**\n",
    "\n",
    ">* **607,555** missing values:\n",
    ">   * authors: **60,360**\n",
    ">   * published_date: **58,455**\n",
    ">   * description: **90,746**\n",
    ">   * isbn_10: **58,391**\n",
    ">   * isbn_13: **91,305**\n",
    ">   * page_count: **59,659**\n",
    ">   * categories: **72,033**\n",
    ">   * maturity_rating: **58,303**\n",
    ">   * language: **58,303**\n",
    "\n",
    ">* No duplicates"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preparation\n",
    "> The goal of the Data Preparation phase is to prepare the final data set(s) for modeling. It has five tasks:\n",
    "\n",
    ">   * Select Data\n",
    ">   * Clean Data\n",
    ">   * Construct Data\n",
    ">   * Integrate Data\n",
    ">   * Format Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Select Data\n",
    "> The aim of this section is to determine which datasets will be used and document reasons for inclusion/exclusion."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Clean Data\n",
    "> The aim of this section is to identify and correct (or remove) corrupt or inaccurate records from the datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a superclass to clean the data\n",
    "class DataCleaning:\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def drop_null_rows(self):\n",
    "        \"\"\"Drops rows with null values.\"\"\"\n",
    "        self.data = self.data.dropna()\n",
    "        return self.data\n",
    "\n",
    "    def drop_duplicate_rows(self):\n",
    "        \"\"\"Drops duplicate rows.\"\"\"\n",
    "        self.data = self.data.drop_duplicates()\n",
    "        return self.data\n",
    "\n",
    "    def handle_missing_values(self, column, method, value=None):\n",
    "        \"\"\"Handles missing values in a specified column.\n",
    "\n",
    "        The method parameter take one of the following:\n",
    "        \"drop\": Drops rows with missing values in the specified column.\n",
    "        \"fill\": Fills missing values with the specified value.\n",
    "        \"interpolate\": Interpolates missing values using linear interpolation.\n",
    "        \"\"\"\n",
    "        if method == \"drop\":\n",
    "            self.data = self.data.dropna(subset=[column])\n",
    "        elif method == \"fill\":\n",
    "            self.data[column] = self.data[column].fillna(value)\n",
    "        elif method == \"interpolate\":\n",
    "            self.data[column] = self.data[column].interpolate()\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Invalid value for method parameter. Valid values are 'drop', 'fill', and 'interpolate'.\"\n",
    "            )\n",
    "        return self.data\n",
    "\n",
    "    def convert_column_data_type(self, column, data_type):\n",
    "        \"\"\"Converts the data type of a specified column.\"\"\"\n",
    "        self.data[column] = self.data[column].astype(data_type)\n",
    "        return self.data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1 [`books`](./data/BX-Books.csv)\n",
    "As seen earlier, the [`books`](./data/BX-Books.csv) dataset contains **271,360** rows and **8** columns. The columns are:\n",
    "\n",
    ">   * **ISBN**: International Standard Book Number (ISBN 10)\n",
    ">   * **Book-Title**: Title of the book\n",
    ">   * **Book-Author**: Author of the book\n",
    ">   * **Year-Of-Publication**: Year the book was published\n",
    ">   * **Publisher**: Publisher of the book\n",
    ">   * **Image-URL-S**: Small image of the book\n",
    ">   * **Image-URL-M**: Medium image of the book\n",
    ">   * **Image-URL-L**: Large image of the book\n",
    "\n",
    "The cleaning process for the dataset will revolve around the following questions:\n",
    "\n",
    "1. How will we handle the 6 missing values (that we identified earlier)?\n",
    "2. Though there aren't any duplicate records, do the individual columns have any duplicates? Are these duplicates erroneous?\n",
    "3. Is there any invalid data?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.1.1 `ISBN`\n",
    "> [**ISBN**](https://isbn-information.com/the-10-digit-isbn.html) (International Standard Book Number), is a unique numeric commercial book identifier. It is 10 or 13 digits long. The ISBN-10 is 10 digits long and is made up of 9 digits plus a check digit (which may be 'X') and the ISBN-13 is 13 digits long and is made up of 12 digits plus a check digit.\n",
    "\n",
    "Cleaning the `ISBN` column will involve the following steps:\n",
    "* Check whether we are dealing with ISBN-10 or ISBN-13\n",
    "* Check for and inspect any invalid ISBNs\n",
    "* Check for and inspect any duplicate ISBNs\n",
    "\n",
    "**Note**:\n",
    "\n",
    "> We will be using the [Google Books API](https://developers.google.com/books) if we need to manually cross-check the validity of the ISBNs in this dataset. In order to check an ISBN, append the ISBN-10 of the book to the end of the following url:\n",
    "> \n",
    "> > `https://www.googleapis.com/books/v1/volumes?q=isbn:`\n",
    "> \n",
    ">For example, to check the validity of the ISBN-10 `0441172717`, you would append it to the url as follows: \n",
    ">\n",
    ">> `https://www.googleapis.com/books/v1/volumes?q=isbn:0441172717`\n",
    ">\n",
    ">If the ISBN is valid, the API will return a JSON object with the book's information. If the ISBN is invalid, the API will return an empty JSON object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subclass that will be used to clean the ISBN column\n",
    "class CleanISBN:\n",
    "    \"\"\"This class is used to inspect and clean the ISBN column.\"\"\"\n",
    "\n",
    "    def __init__(self, df, col):\n",
    "\n",
    "        # Get the DataFrame\n",
    "        self.df = df\n",
    "\n",
    "        # Get the column\n",
    "        self.column = df[col]\n",
    "\n",
    "        # Display distribution of the lengths of the values in the column\n",
    "        self.length = df[col].str.len().value_counts()\n",
    "\n",
    "    # --- FUNCTIONS ---\n",
    "\n",
    "    # Define a function to convert the ASINs to their respective ISBN-10s\n",
    "    def convert_asin(isbn):\n",
    "        \"\"\"This function is used to convert the ASINs to ISBN-10.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    # Define a function to correct the ISBNs with invalid lengths\n",
    "    def correct_length(isbn):\n",
    "        \"\"\"This function is used to correct the isbns containing invalid lengths.\"\"\"\n",
    "        \n",
    "        isbn = str(isbn)\n",
    "        \n",
    "        # Correction of ISBNs that are less than 10 characters long\n",
    "        if len(isbn) < 10:\n",
    "            \n",
    "            # Calculate the number of \"0\"s that are missing\n",
    "            missing = (10 - len(isbn)) * \"0\"\n",
    "            \n",
    "            # Prepend the missing characters to the ISBN\n",
    "            isbn = missing + isbn\n",
    "            \n",
    "            return isbn\n",
    "        \n",
    "        # Correction of ISBNs that are more than 10 characters long\n",
    "        if len(isbn) > 10:\n",
    "            \n",
    "            # Try to extract the first 10 characters that are either numeric or \"X\"\n",
    "            try:\n",
    "                pattern = r\"^[0-9X]{10}\"\n",
    "                isbn = re.search(pattern, isbn).group(0)\n",
    "                \n",
    "                return isbn\n",
    "            \n",
    "            # If the ISBN does not contain enough numeric characters, return the original ISBN\n",
    "            except:\n",
    "                return isbn\n",
    "\n",
    "    # --- METHODS ---\n",
    "\n",
    "    # Define a method to inspect and clean the invalid characters\n",
    "    def invalid_char(self, action: str, check: str = \"invalid\"):\n",
    "        \"\"\"This method is used to inspect or clean the invalid characters.\"\"\"\n",
    "\n",
    "        if action == \"inspect\":\n",
    "\n",
    "            if check == \"invalid\":\n",
    "                # Query the records that have an ISBN with any non-numeric characters (except 'X')\n",
    "                invalid_char = self.df.query(\"ISBN.str.contains('[^\\dX]')\")\n",
    "\n",
    "            if check == \"lowercase\":\n",
    "                # Query the records that contain lowercase characters\n",
    "                invalid_char = self.df.query(\"ISBN.str.contains('[a-z]')\")\n",
    "\n",
    "            if check == \"alphabetical\":\n",
    "                # Query the records that contain alphabetical characters (except 'X')\n",
    "                invalid_char = self.df.query(\"ISBN.str.contains('[A-WY-Za-wy-z]')\")\n",
    "\n",
    "            if check == \"non-alphanumeric\":\n",
    "                # Query the records that contain non-alphanumeric characters\n",
    "                invalid_char = self.df.query(\"ISBN.str.contains('[\\W_]')\")\n",
    "\n",
    "            # Print the number of records with invalid characters in the ISBN column\n",
    "            print(\n",
    "                f\"There are {invalid_char.shape[0]} records with {check} characters in their ISBNs.\"\n",
    "            )\n",
    "\n",
    "            # Preview the invalid ISBN records\n",
    "            return invalid_char.iloc[:, 0:5].head()\n",
    "\n",
    "        if action == \"clean\":\n",
    "\n",
    "            # Convert the ASINs to their respective ISBN-10s\n",
    "            # self.column = self.column.apply(self.convert)\n",
    "\n",
    "            # Convert the ISBNs to uppercase\n",
    "            self.column = self.column.str.upper()\n",
    "\n",
    "            # Replace the non-alphanumeric characters with empty strings\n",
    "            self.column = self.column.str.replace(\"[\\W_]\", \"\")\n",
    "\n",
    "            return self.column\n",
    "\n",
    "    # Define a method to inspect and clean the invalid lengths\n",
    "    def invalid_length(self, action: str, check: str = \"invalid\"):\n",
    "        \"\"\"This method is used to inspect or clean the invalid lengths.\"\"\"\n",
    "\n",
    "        if action == \"inspect\":\n",
    "\n",
    "            if check == \"invalid\":\n",
    "                # Query the records that have an ISBN with a length other than 10\n",
    "                invalid_length = self.df.query(\"ISBN.str.len() != 10\")\n",
    "\n",
    "            if check == \"less\":\n",
    "                # Query the records that have an ISBN with a length less than 10\n",
    "                invalid_length = self.df.query(\"ISBN.str.len() < 10\")\n",
    "\n",
    "            if check == \"greater\":\n",
    "                # Query the records that have an ISBN with a length greater than 10\n",
    "                invalid_length = self.df.query(\"ISBN.str.len() > 10\")\n",
    "\n",
    "            # Print the number of records with invalid lengths in the ISBN column\n",
    "            print(f\"There are {invalid_length.shape[0]} records with ISBN lengths that are {check}.\")\n",
    "\n",
    "            # Preview the invalid ISBN records\n",
    "            return invalid_length.iloc[:, 0:5].head()\n",
    "\n",
    "        if action == \"clean\":\n",
    "            \n",
    "            # Apply the 'correct_length' function to the ISBN column\n",
    "            self.column = self.column.apply(self.correct_length)\n",
    "            \n",
    "            return self.column\n",
    "\n",
    "    # Define a method to inspect and clean the invalid check digits\n",
    "    def invalid_check_digit(self, action: str):\n",
    "        \"\"\"This method is used to inspect or clean the invalid check digits.\"\"\"\n",
    "\n",
    "        if action == \"inspect\":\n",
    "            pass\n",
    "\n",
    "        if action == \"clean\":\n",
    "            pass\n",
    "\n",
    "\n",
    "# Instantiate the 'CleanISBN' class\n",
    "clean_isbn = CleanISBN(books, \"ISBN\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1**: *Are we dealing with ISBN-10 or ISBN-13?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10    271356\n",
       "13         3\n",
       "11         1\n",
       "Name: ISBN, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the distribution of the lengths of the individual values in the 'ISBN' column\n",
    "clean_isbn.length"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Majority of the values in the `ISBN` column seem to be of the **ISBN-10** format. It is also worth noting that there are some 3 values that seem to be of the ISBN-13 format, and 1 value that has 11 characters. These will be investigated further as we proceed. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2**: *Are there any invalid ISBNs?*\n",
    "\n",
    "We have confirmed that we are dealing with ISBN-10s. Therefore, we will check for invalid ISBN-10 values. This process will involve checking for the following:\n",
    "> * Invalid characters (i.e. non-numeric characters other than 'X')\n",
    "> * Invalid length (i.e. length other than 10)\n",
    "> * Invalid check digit (i.e. the last digit does not mathematically add up)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by checking for invalid characters. This process will mainly utilize the pandas string method [`.contains()`](https://pandas.pydata.org/docs/reference/api/pandas.Series.str.contains.html#pandas.Series.str.contains) coupled with regular expressions to identify the invalid characters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 529 records with invalid characters in their ISBNs.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5726</th>\n",
       "      <td>096788330x</td>\n",
       "      <td>Duncan Delaney and the Cadillac of Doom</td>\n",
       "      <td>A. L. Haskett</td>\n",
       "      <td>2000</td>\n",
       "      <td>Jonlin Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6291</th>\n",
       "      <td>B00009ANY9</td>\n",
       "      <td>Cane River</td>\n",
       "      <td>Lalita Tademy</td>\n",
       "      <td>2001</td>\n",
       "      <td>Warner Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6635</th>\n",
       "      <td>002542730x</td>\n",
       "      <td>Politically Correct Bedtime Stories: Modern Ta...</td>\n",
       "      <td>James Finn Garner</td>\n",
       "      <td>1994</td>\n",
       "      <td>John Wiley &amp;amp; Sons Inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9907</th>\n",
       "      <td>039330678x</td>\n",
       "      <td>Every Person's Life Is Worth a Novel</td>\n",
       "      <td>Erving Polster</td>\n",
       "      <td>1990</td>\n",
       "      <td>W W Norton &amp;amp; Co Inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10272</th>\n",
       "      <td>B0000A2U93</td>\n",
       "      <td>Carmilla</td>\n",
       "      <td>Joseph Sheridan Le Fanu</td>\n",
       "      <td>0</td>\n",
       "      <td>Soft Editions Ltd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ISBN                                         Book-Title  \\\n",
       "5726   096788330x            Duncan Delaney and the Cadillac of Doom   \n",
       "6291   B00009ANY9                                         Cane River   \n",
       "6635   002542730x  Politically Correct Bedtime Stories: Modern Ta...   \n",
       "9907   039330678x               Every Person's Life Is Worth a Novel   \n",
       "10272  B0000A2U93                                           Carmilla   \n",
       "\n",
       "                   Book-Author Year-Of-Publication                  Publisher  \n",
       "5726             A. L. Haskett                2000               Jonlin Books  \n",
       "6291             Lalita Tademy                2001               Warner Books  \n",
       "6635         James Finn Garner                1994  John Wiley &amp; Sons Inc  \n",
       "9907            Erving Polster                1990    W W Norton &amp; Co Inc  \n",
       "10272  Joseph Sheridan Le Fanu                   0          Soft Editions Ltd  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect the column for records with invalid characters in their ISBNs\n",
    "clean_isbn.invalid_char(action='inspect', check='invalid')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These **529** invalid ISBNs could be caused by the following:\n",
    "* **Lowercase characters** (i.e. 'x' instead of 'X')\n",
    "* **Alphabetical characters** (i.e. 'A', 'B', 'C', etc. except 'X')\n",
    "* **Non-alphanumeric characters** (i.e. '!', '@', ' ', etc.)\n",
    "\n",
    "We will be inspecting the ISBNs to ascertain the cause of the invalid characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 411 records with lowercase characters in their ISBNs.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5726</th>\n",
       "      <td>096788330x</td>\n",
       "      <td>Duncan Delaney and the Cadillac of Doom</td>\n",
       "      <td>A. L. Haskett</td>\n",
       "      <td>2000</td>\n",
       "      <td>Jonlin Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6635</th>\n",
       "      <td>002542730x</td>\n",
       "      <td>Politically Correct Bedtime Stories: Modern Ta...</td>\n",
       "      <td>James Finn Garner</td>\n",
       "      <td>1994</td>\n",
       "      <td>John Wiley &amp;amp; Sons Inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9907</th>\n",
       "      <td>039330678x</td>\n",
       "      <td>Every Person's Life Is Worth a Novel</td>\n",
       "      <td>Erving Polster</td>\n",
       "      <td>1990</td>\n",
       "      <td>W W Norton &amp;amp; Co Inc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11925</th>\n",
       "      <td>014062080x</td>\n",
       "      <td>The Scarlet Letter (Penguin Popular Classics)</td>\n",
       "      <td>Nathaniel Hawthorne</td>\n",
       "      <td>1994</td>\n",
       "      <td>Penguin Books Ltd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14621</th>\n",
       "      <td>042519065x</td>\n",
       "      <td>Wings of Fire</td>\n",
       "      <td>Dale Brown</td>\n",
       "      <td>2003</td>\n",
       "      <td>Berkley Publishing Group</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ISBN                                         Book-Title  \\\n",
       "5726   096788330x            Duncan Delaney and the Cadillac of Doom   \n",
       "6635   002542730x  Politically Correct Bedtime Stories: Modern Ta...   \n",
       "9907   039330678x               Every Person's Life Is Worth a Novel   \n",
       "11925  014062080x      The Scarlet Letter (Penguin Popular Classics)   \n",
       "14621  042519065x                                      Wings of Fire   \n",
       "\n",
       "               Book-Author Year-Of-Publication                  Publisher  \n",
       "5726         A. L. Haskett                2000               Jonlin Books  \n",
       "6635     James Finn Garner                1994  John Wiley &amp; Sons Inc  \n",
       "9907        Erving Polster                1990    W W Norton &amp; Co Inc  \n",
       "11925  Nathaniel Hawthorne                1994          Penguin Books Ltd  \n",
       "14621           Dale Brown                2003   Berkley Publishing Group  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query the records for lowercase characters in the ISBNs\n",
    "clean_isbn.invalid_char(action='inspect', check='lowercase')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are **411** ISBNs that contain lowercase characters. These characters will be replaced with their uppercase counterparts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 114 records with alphabetical characters in their ISBNs.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6291</th>\n",
       "      <td>B00009ANY9</td>\n",
       "      <td>Cane River</td>\n",
       "      <td>Lalita Tademy</td>\n",
       "      <td>2001</td>\n",
       "      <td>Warner Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10272</th>\n",
       "      <td>B0000A2U93</td>\n",
       "      <td>Carmilla</td>\n",
       "      <td>Joseph Sheridan Le Fanu</td>\n",
       "      <td>0</td>\n",
       "      <td>Soft Editions Ltd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11185</th>\n",
       "      <td>B0000633PU</td>\n",
       "      <td>The Story of Aladdin and the Wonderful Lamp</td>\n",
       "      <td>S. Lane Poole</td>\n",
       "      <td>0</td>\n",
       "      <td>Renaissance eBooks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13862</th>\n",
       "      <td>B00007FYKO</td>\n",
       "      <td>Bloodcurdling Tales of Horror and the Macabre:...</td>\n",
       "      <td>H. P. Lovecraft</td>\n",
       "      <td>0</td>\n",
       "      <td>Ballantine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13865</th>\n",
       "      <td>B00009APKU</td>\n",
       "      <td>Moby Dick</td>\n",
       "      <td>Herman Melville</td>\n",
       "      <td>0</td>\n",
       "      <td>Outrigger Publishing, LLC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ISBN                                         Book-Title  \\\n",
       "6291   B00009ANY9                                         Cane River   \n",
       "10272  B0000A2U93                                           Carmilla   \n",
       "11185  B0000633PU        The Story of Aladdin and the Wonderful Lamp   \n",
       "13862  B00007FYKO  Bloodcurdling Tales of Horror and the Macabre:...   \n",
       "13865  B00009APKU                                          Moby Dick   \n",
       "\n",
       "                   Book-Author Year-Of-Publication                  Publisher  \n",
       "6291             Lalita Tademy                2001               Warner Books  \n",
       "10272  Joseph Sheridan Le Fanu                   0          Soft Editions Ltd  \n",
       "11185            S. Lane Poole                   0         Renaissance eBooks  \n",
       "13862          H. P. Lovecraft                   0                 Ballantine  \n",
       "13865          Herman Melville                   0  Outrigger Publishing, LLC  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query the records containing alphabetical characters except 'X' in the ISBNs\n",
    "clean_isbn.invalid_char(action='inspect', check='alphabetical')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are **118** ISBNs that contain alphabetical characters. Upon doing research, it turns out that some of these values are valid. However, they are not in the ISBN-10 format. They are instead using Amazon's proprietary ASIN (Amazon Standard Identification Number).\n",
    "\n",
    "> [**ASIN**](https://www.nchannel.com/blog/amazon-asin-what-is-an-asin-number/) (Amazon Standard Identification Number) is a 10-character alphanumeric unique identifier assigned by Amazon.com and its partners for product identification within the Amazon organization. ASINs are used to identify products in Amazon listings, product advertising API, etc.\n",
    "\n",
    "As these are not too many ISBNs, we will attempt to correct them by first checking if the books already exist in the dataset. If they do no, we will replace the ASIN with the correct record's ISBN. If they don't, we will attempt to manually search the web for and update the ISBNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 records with non-alphanumeric characters in their ISBNs.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>111808</th>\n",
       "      <td>0486404242\\t</td>\n",
       "      <td>War in Kind: And Other Poems (Dover Thrift Edi...</td>\n",
       "      <td>Stephen Crane</td>\n",
       "      <td>1998</td>\n",
       "      <td>Dover Publications</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171206</th>\n",
       "      <td>3518365479&lt;90</td>\n",
       "      <td>Suhrkamp TaschenbÃƒ?Ã‚Â¼cher, Nr.47, Frost</td>\n",
       "      <td>Thomas Bernhard</td>\n",
       "      <td>1972</td>\n",
       "      <td>Suhrkamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251424</th>\n",
       "      <td>3442248027  3</td>\n",
       "      <td>Diamond Age. Die Grenzwelt.</td>\n",
       "      <td>Neal Stephenson</td>\n",
       "      <td>2000</td>\n",
       "      <td>Goldmann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251649</th>\n",
       "      <td>0385722206  0</td>\n",
       "      <td>Balzac and the Little Chinese Seamstress : A N...</td>\n",
       "      <td>DAI SIJIE</td>\n",
       "      <td>2002</td>\n",
       "      <td>Anchor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ISBN                                         Book-Title  \\\n",
       "111808   0486404242\\t  War in Kind: And Other Poems (Dover Thrift Edi...   \n",
       "171206  3518365479<90            Suhrkamp TaschenbÃƒ?Ã‚Â¼cher, Nr.47, Frost   \n",
       "251424  3442248027  3                        Diamond Age. Die Grenzwelt.   \n",
       "251649  0385722206  0  Balzac and the Little Chinese Seamstress : A N...   \n",
       "\n",
       "            Book-Author Year-Of-Publication           Publisher  \n",
       "111808    Stephen Crane                1998  Dover Publications  \n",
       "171206  Thomas Bernhard                1972            Suhrkamp  \n",
       "251424  Neal Stephenson                2000            Goldmann  \n",
       "251649        DAI SIJIE                2002              Anchor  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query the records containing non-alphanumeric characters in the ISBNs\n",
    "clean_isbn.invalid_char(action='inspect', check='non-alphanumeric')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the preview above, we see that there are 4 records containing non-alphanumeric (Neither alphabetical or numerical) characters. Therefore, to correct these invalid characters, we will simply replace them with empty strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the invalid characters in the ISBNs\n",
    "books['ISBN'] = clean_isbn.invalid_char(action='clean')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When it comes to invalid length, we had earlier identified 4 ISBNs that were not 10 characters/digits long. In addition, after removing any invalid characters, this number may have changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 records with ISBN lengths that are invalid.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>171206</th>\n",
       "      <td>351836547990</td>\n",
       "      <td>Suhrkamp TaschenbÃƒ?Ã‚Â¼cher, Nr.47, Frost</td>\n",
       "      <td>Thomas Bernhard</td>\n",
       "      <td>1972</td>\n",
       "      <td>Suhrkamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251424</th>\n",
       "      <td>34422480273</td>\n",
       "      <td>Diamond Age. Die Grenzwelt.</td>\n",
       "      <td>Neal Stephenson</td>\n",
       "      <td>2000</td>\n",
       "      <td>Goldmann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251649</th>\n",
       "      <td>03857222060</td>\n",
       "      <td>Balzac and the Little Chinese Seamstress : A N...</td>\n",
       "      <td>DAI SIJIE</td>\n",
       "      <td>2002</td>\n",
       "      <td>Anchor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ISBN                                         Book-Title  \\\n",
       "171206  351836547990            Suhrkamp TaschenbÃƒ?Ã‚Â¼cher, Nr.47, Frost   \n",
       "251424   34422480273                        Diamond Age. Die Grenzwelt.   \n",
       "251649   03857222060  Balzac and the Little Chinese Seamstress : A N...   \n",
       "\n",
       "            Book-Author Year-Of-Publication Publisher  \n",
       "171206  Thomas Bernhard                1972  Suhrkamp  \n",
       "251424  Neal Stephenson                2000  Goldmann  \n",
       "251649        DAI SIJIE                2002    Anchor  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query the records with invalid ISBN lengths\n",
    "clean_isbn.invalid_length(action='inspect', check='invalid')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a total of 3 records with invalid ISBN lengths. When it comes to correcting ISBNs of invalid lengths, there are 2 main approaches:\n",
    "\n",
    "1. ISBNs less than 10 characters long can be padded with leading zeros. This may have resulted from being saved in a numerical format which automatically removes leading zeros\n",
    "\n",
    "> Example:\n",
    ">\n",
    "> An ISBN of the form `123456789` can be padded with leading zeros to become `0123456789`.\n",
    "\n",
    "1. ISBNs greater than 10 characters long can be truncated to 10 characters long.\n",
    "\n",
    "> Example:\n",
    ">\n",
    "> An ISBN of the form `1234567890123` can be truncated to become `1234567890`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 0 records with ISBN lengths that are less.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ISBN, Book-Title, Book-Author, Year-Of-Publication, Publisher]\n",
       "Index: []"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query the records with ISBN lengths that are less than 10 characters\n",
    "clean_isbn.invalid_length(action='inspect', check='less')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There aren't any records that have ISBNs that are less than 10 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 records with ISBN lengths that are greater.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISBN</th>\n",
       "      <th>Book-Title</th>\n",
       "      <th>Book-Author</th>\n",
       "      <th>Year-Of-Publication</th>\n",
       "      <th>Publisher</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>171206</th>\n",
       "      <td>351836547990</td>\n",
       "      <td>Suhrkamp TaschenbÃƒ?Ã‚Â¼cher, Nr.47, Frost</td>\n",
       "      <td>Thomas Bernhard</td>\n",
       "      <td>1972</td>\n",
       "      <td>Suhrkamp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251424</th>\n",
       "      <td>34422480273</td>\n",
       "      <td>Diamond Age. Die Grenzwelt.</td>\n",
       "      <td>Neal Stephenson</td>\n",
       "      <td>2000</td>\n",
       "      <td>Goldmann</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251649</th>\n",
       "      <td>03857222060</td>\n",
       "      <td>Balzac and the Little Chinese Seamstress : A N...</td>\n",
       "      <td>DAI SIJIE</td>\n",
       "      <td>2002</td>\n",
       "      <td>Anchor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ISBN                                         Book-Title  \\\n",
       "171206  351836547990            Suhrkamp TaschenbÃƒ?Ã‚Â¼cher, Nr.47, Frost   \n",
       "251424   34422480273                        Diamond Age. Die Grenzwelt.   \n",
       "251649   03857222060  Balzac and the Little Chinese Seamstress : A N...   \n",
       "\n",
       "            Book-Author Year-Of-Publication Publisher  \n",
       "171206  Thomas Bernhard                1972  Suhrkamp  \n",
       "251424  Neal Stephenson                2000  Goldmann  \n",
       "251649        DAI SIJIE                2002    Anchor  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query the records with ISBN lengths that are greater than 10 characters\n",
    "clean_isbn.invalid_length(action='inspect', check='greater')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 3 records with ISBNs that are greater than 10 characters. However, if we take the first 10 characters and cross-check them against the Google-Books API, they each return data belonging to the books that they have been assigned to in the dataset. Therefore, as we had referenced earlier, we will be truncating the ISBNs to the first 10 characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the ISBNs with invalid lengths\n",
    "books['ISBN'] = clean_isbn.invalid_length(action='clean')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3**: *Are there any duplicates?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for any duplicated ISBNs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.1.2 `Book-Title`\n",
    "Cleaning the `Book-Title` column will involve the following steps:\n",
    "* Check for invalid characters (probably resulting from wrong encoding) and correct them where possible"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.1.3 `Book-Author`\n",
    "Cleaning the `Book-Author` column will involve the following steps:\n",
    "* Check for invalid characters (probably resulting from wrong encoding) and correct them where possible\n",
    "* Check for instances of misspelled names or cases where the author's name has been written differently (e.g. 'Ann M. Martin', 'Ann Martin', 'Ann M Martin)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.2.1.3 `Year-Of-Publication`\n",
    "Cleaning the `Book-Author` column will involve the following steps:\n",
    "* Check for invalid characters (probably resulting from wrong encoding) and correct them where possible\n",
    "* Check for instances of misspelled names or cases where the author's name has been written differently (e.g. 'Ann M. Martin', 'Ann Martin', 'Ann M Martin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to clean the ISBNs\n",
    "def clean_isbn(isbn: str) -> str:\n",
    "    \"\"\"This function is used to clean the 'ISBN' column.\"\"\"\n",
    "    \n",
    "    # Remove any form of punctuation or whitespace\n",
    "    isbn = isbn.translate(str.maketrans('', '', punctuation)).replace(\" \", \"\")\n",
    "    \n",
    "    # Convert the ISBN to uppercase\n",
    "    isbn = isbn.upper()\n",
    "    \n",
    "    # Remove any characters that are not digits or X\n",
    "    isbn = re.sub(r\"[^0-9X]\", \"\", isbn)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Books Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the shape of the books dataset before dealing with erraneous ISBN values\n",
    "books.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the books ISBN numbers to upper string and replacing the quotation marks\n",
    "books['ISBN'] = books['ISBN'].str.upper().str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for duplicates \n",
    "books['ISBN'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to correct the ISBN that are not in correct format\n",
    "def correct_isbn(isbn):\n",
    "    isbn = str(isbn)\n",
    "    fill = \"0\"\n",
    "    if len(isbn) < 10:\n",
    "        missing = 10 - len(isbn)\n",
    "        new_isbn = (fill * missing) + isbn\n",
    "        return new_isbn\n",
    "    elif len(isbn) > 10:\n",
    "        try:\n",
    "            pattern = r\"^[0-9Xx]{10}\"\n",
    "            result = re.search(pattern, isbn)\n",
    "            new_isbn = result.group(0)\n",
    "            return new_isbn\n",
    "        except:\n",
    "            print(isbn)\n",
    "            return isbn\n",
    "\n",
    "    return isbn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying the function to the books ISBN column\n",
    "books['ISBN'] = books['ISBN'].apply(correct_isbn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping duplicates\n",
    "books.drop_duplicates(subset=['ISBN'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the shape of the new dataset after dealing with duplicates\n",
    "books.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge books dataset to books_extra\n",
    "books_data = books.merge(books_extra, right_on = 'join_isbn_10', left_on = 'ISBN', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate the 'DescribeData' class for the merged dataset\n",
    "bk_upgrd = DescribeData(books_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bk_upgrd.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bk_upgrd.df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bk_upgrd.missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate the 'datacleaning' class for the merged dataset\n",
    "data_cleaning = DataCleaning(books_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping rows with null values in the description column\n",
    "books_data = data_cleaning.handle_missing_values(column=\"description\", method=\"drop\")\n",
    "books_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All entries with no description are dropped because it is a critical feature that will be used in our recommendation system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping unwanted columns from the merged dataset\n",
    "book_data = books_data.drop(['Image-URL-L', 'Image-URL-M','isbn_10', 'isbn_13','join_isbn_10'], axis=1)\n",
    "book_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for missing values after dropping unwanted columns\n",
    "book_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the years of publication\n",
    "book_data['Year-Of-Publication'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_data.loc[book_data['Year-Of-Publication'] == '0',:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Replace values where the \"Year-Of-Publication\" is 0 with the corresponding value in the \"published-data\" column\n",
    "book_data[\"Year-Of-Publication\"] = book_data[\"Year-Of-Publication\"].mask(book_data[\"Year-Of-Publication\"] == '0', book_data[\"published_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirming the years with 0 have been replaced \n",
    "book_data.loc[book_data['Year-Of-Publication'] == '0',:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#investigating the rows having 'DK Publishing Inc' as year Of Publication\n",
    "book_data.loc[book_data['Year-Of-Publication'] == 'DK Publishing Inc',:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be observed that there are some incorrect entries in Year-Of-Publication field since publisher names 'DK Publishing Inc' has been incorrectly recorded as Year-Of-Publication in dataset due to some errors in csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Since bookAuthor is incorrectly loaded with publication year; making required corrections\n",
    "#ISBN '0789466953'\n",
    "book_data.loc[book_data.ISBN == '0789466953','Year-Of-Publication'] = 2000\n",
    "book_data.loc[book_data.ISBN == '0789466953','Book-Author'] = \"James Buckley\"\n",
    "book_data.loc[book_data.ISBN == '0789466953','Publisher'] = \"DK Publishing Inc\"\n",
    "book_data.loc[book_data.ISBN == '0789466953','Book-Title'] = \"DK Readers: Creating the X-Men, How Comic Books Come to Life (Level 4: Proficient Readers)\"\n",
    "\n",
    "#ISBN '078946697X'\n",
    "book_data.loc[book_data.ISBN == '078946697X','Year-Of-Publication'] = 2000\n",
    "book_data.loc[book_data.ISBN == '078946697X','Book-Author'] = \"Michael Teitelbaum\"\n",
    "book_data.loc[book_data.ISBN == '078946697X','Publisher'] = \"DK Publishing Inc\"\n",
    "book_data.loc[book_data.ISBN == '078946697X','Book-Title'] = \"DK Readers: Creating the X-Men, How It All Began (Level 4: Proficient Readers)\"\n",
    "\n",
    "#rechecking that the errors have been corrected\n",
    "book_data.loc[(book_data.ISBN == '0789466953') | (book_data.ISBN == '078946697X'),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#investigating the rows having 'Gallimard' as yearOfPublication\n",
    "book_data.loc[book_data['Year-Of-Publication'] == 'Gallimard',:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making required corrections for Gallimard while keeping other fields intact\n",
    "book_data.loc[book_data.ISBN == '2070426769','Year-Of-Publication'] = 2003\n",
    "book_data.loc[book_data.ISBN == '2070426769','Book-Author'] = \"Jean-Marie Gustave Le ClÃƒ?Ã‚Â©zio\"\n",
    "book_data.loc[book_data.ISBN == '2070426769','Publisher'] = \"Gallimard\"\n",
    "book_data.loc[book_data.ISBN == '2070426769','Book-Title'] = \"Peuple du ciel, suivi de 'Les Bergers\"\n",
    "\n",
    "#rechecking that the corrections have been made\n",
    "book_data.loc[book_data.ISBN == '2070426769',:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting year of publication to integers\n",
    "book_data['Year-Of-Publication']=pd.to_numeric((book_data['Year-Of-Publication']), errors='coerce')\n",
    "\n",
    "print(sorted(book_data['Year-Of-Publication'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing years above 2004 and those with no value with the median\n",
    "book_data.loc[(book_data['Year-Of-Publication'] > 2004) | (book_data['Year-Of-Publication'] == 0),'Year-Of-Publication'] = np.NAN\n",
    "\n",
    "#replacing NaNs with median value of Year-Of-Publication\n",
    "book_data['Year-Of-Publication'].fillna(round(book_data['Year-Of-Publication'].median()), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the 'datacleaning' class for the 'published' DataFrame\n",
    "data_cleaning = DataCleaning(book_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_data = data_cleaning.convert_column_data_type('Year-Of-Publication', int)\n",
    "print(sorted(book_data['Year-Of-Publication'].unique())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the published date column since it will not be required for analysis\n",
    "book_data = book_data.drop(['published_date'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exploring 'publisher' column\n",
    "book_data.loc[book_data.Publisher.isnull(),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filling Nan of Publisher with its publisher\n",
    "book_data.Publisher.fillna('Bantam', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exploring 'Page count' column\n",
    "book_data.loc[book_data.page_count.isnull(),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'page_count' to numeric data type\n",
    "book_data['page_count'] = pd.to_numeric(book_data['page_count'], errors='coerce')\n",
    "# Replace any NaN values with a placeholder value\n",
    "book_data['page_count'].fillna(-1, inplace=True)\n",
    "# Convert the 'float_column' to integer data type\n",
    "book_data['page_count'] = book_data['page_count'].round().astype(int)\n",
    "# preview data set\n",
    "book_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspecting page_count entries with missing data with the placeholder -1\n",
    "book_data.loc[book_data['page_count'] == -1,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 490 missing values in page_count that were replaced with -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exploring the categories column\n",
    "book_data.loc[book_data.categories.isnull(),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling NaN of categories with None\n",
    "book_data.categories.fillna('None',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the categories column we have the categories names in a list\n",
    "# Remove the brackets and quotation marks from the 'categories' column\n",
    "book_data['categories'] = book_data['categories'].str.strip('[]')\n",
    "book_data['categories'] = book_data['categories'].str.strip(\"''\")\n",
    "# preview data set\n",
    "book_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exploring the authors column\n",
    "book_data.loc[book_data.authors.isnull(),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a fuction to handle missing data in authors column\n",
    "def replace_missing_values(df):\n",
    " # Create a boolean mask indicating which rows in the \"authors\" column have missing values\n",
    " mask = df['authors'].isnull()\n",
    " \n",
    " # Get the index values for the rows where the value in the \"authors\" column is missing\n",
    " indexes = df.loc[mask, 'authors'].index\n",
    " \n",
    " # Use the index values to select the corresponding values in the \"book_authors\" column\n",
    " # and assign these values to the \"authors\" column for the rows where the value is missing\n",
    " df.loc[indexes, 'authors'] = df.loc[indexes, 'Book-Author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing missing authors with corresponding book-author\n",
    "replace_missing_values(book_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rechecking for missing values in authors\n",
    "book_data['authors'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The category column has the categories in list which is corrected by removing the brackets and quotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the authors column we have the authors names in a list\n",
    "# Defining a function to remove the brackets and quotation marks from the 'authors' column\n",
    "def authors_split(authors):\n",
    "    try:\n",
    "        authors = authors\\\n",
    "            .replace(\"['\", \"\")\\\n",
    "            .replace(\"']\", \"\")\\\n",
    "            .replace(\"', '\", \", \")\\\n",
    "            .replace(\"','\", \", \")\\\n",
    "            .replace(\"' ,'\", \", \")\\\n",
    "            .replace('[\"', '')\\\n",
    "            .replace('\"]', '')\\\n",
    "            .replace('\", \"', ', ')\\\n",
    "            .replace('\",\"', ', ')\\\n",
    "            .replace('\" ,\"', ', ')\\\n",
    "            .split(\", \")\n",
    "            \n",
    "        return authors\n",
    "    \n",
    "    except:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying the function to the authors column\n",
    "book_data['authors'] = book_data['authors'].apply(authors_split)\n",
    "book_data['authors'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separating the different authors from the created list\n",
    "book_data = book_data.explode(column='authors', ignore_index = True)\n",
    "book_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting values in the maturity rating column to lowercase\n",
    "book_data['maturity_rating'] = book_data['maturity_rating'].str.lower()\n",
    "book_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirming that all missing values have been dealt with\n",
    "book_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The location column has city, state and country separated by commas. We segregate these into 3 different columns so that we can analyse on the basis of the country of different users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting a string into a list\n",
    "list_ = users.Location.str.split(', ')\n",
    "\n",
    "#empty lists to add values  \n",
    "city = []\n",
    "state = []\n",
    "country = []\n",
    "count_no_state = 0    \n",
    "count_no_country = 0\n",
    "#generating a for loop to add values to the empty lists\n",
    "for i in range(0,len(list_)):\n",
    "    #removing invalid entries in city\n",
    "    if list_[i][0] == ' ' or list_[i][0] == '' or list_[i][0]=='n/a' or list_[i][0] == ',':  \n",
    "        city.append('other')\n",
    "    else:\n",
    "        city.append(list_[i][0].lower())\n",
    "\n",
    "    if(len(list_[i])<2):\n",
    "        state.append('other')\n",
    "        country.append('other')\n",
    "        count_no_state += 1\n",
    "        count_no_country += 1\n",
    "    else:\n",
    "        #removing invalid entries in state\n",
    "        if list_[i][1] == ' ' or list_[i][1] == '' or list_[i][1]=='n/a' or list_[i][1] == ',':   \n",
    "            state.append('other')\n",
    "            count_no_state += 1            \n",
    "        else:\n",
    "            state.append(list_[i][1].lower())\n",
    "        \n",
    "        if(len(list_[i])<3):\n",
    "            country.append('other')\n",
    "            count_no_country += 1\n",
    "        else:\n",
    "            #removing invalid entries in country\n",
    "            if list_[i][2] == ''or list_[i][1] == ',' or list_[i][2] == ' ' or list_[i][2] == 'n/a':\n",
    "                country.append('other')\n",
    "                count_no_country += 1\n",
    "            else:\n",
    "                country.append(list_[i][2].lower())\n",
    "        \n",
    "#dropping the location column from users             \n",
    "users = users.drop('Location',axis=1)\n",
    "\n",
    "#handling cases where city/state from the lists is already given\n",
    "temp = []\n",
    "for ent in city:\n",
    "    c = ent.split('/')            \n",
    "    temp.append(c[0])\n",
    "    \n",
    "#creating a dataframe for city, state and country\n",
    "df_city = pd.DataFrame(temp,columns=['City'])\n",
    "df_state = pd.DataFrame(state,columns=['State'])\n",
    "df_country = pd.DataFrame(country,columns=['Country'])\n",
    "\n",
    "#adding the new dataframes to the original users dataframe \n",
    "users = pd.concat([users, df_city], axis=1)\n",
    "users = pd.concat([users, df_state], axis=1)\n",
    "users = pd.concat([users, df_country], axis=1)\n",
    "\n",
    "#printing the number of countries that do not have values \n",
    "print(count_no_country)\n",
    "\n",
    "#printing the states which didnt have any values\n",
    "print(count_no_state)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop duplicate rows\n",
    "users.drop_duplicates(keep='last', inplace=True)\n",
    "users.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirming that the new dataframes have been added to users\n",
    "users.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for null values\n",
    "users['Age'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with missing values in the Age column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the Age distribution\n",
    "users.Age.hist(bins=[0, 10, 20, 30, 40, 50, 100])\n",
    "plt.title('Age Distribution\\n')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most active users are in the age bracket between 20 to 30 years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for outliers in the age column using a boxplot\n",
    "sns.boxplot(y='Age', data=users)\n",
    "plt.title('Outliers present in the Age column')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the distribution plot the age is skewed to the right and has outliers. Replacing the missing age values and values less than 10 and greater than 80 with the median will be the robust approach since it's not sensitive to extreme values compared to using the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking all values present in the Age column\n",
    "print(sorted(list(users['Age'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting a distribution plot to discover the relevant age bracket \n",
    "sns.distplot(users.Age)\n",
    "plt.title('Age Distribution Plot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evidently, users with ages less than 10 and above 80 are not an appropriate target for our book recommendation system since we assume they will not be able to access a library or use the recommendation system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows where the age column is greater than 10 and less than 80\n",
    "users_filtered = users[(users['Age'] >= 10) & (users['Age'] <= 80)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculating the median for the required ages\n",
    "median = users_filtered['Age'].median()\n",
    "median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the entries less than 10 or greater than 80 with the median\n",
    "users.loc[(users['Age'] < 10) | (users['Age'] > 80), 'Age'] = median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace missing values in the \"age\" column with the median age\n",
    "users['Age'] = users['Age'].fillna(median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the age column to int\n",
    "users['Age'] = pd.to_numeric(users['Age'], downcast='integer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sorted(list(users['Age'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confirming that the missing values have been dealt with\n",
    "users.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratings Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning the ratings ISBN column using the correct_isbn function\n",
    "ratings['ISBN'] = ratings['ISBN'].apply(correct_isbn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting rid of the special characters present in the ISBN column\n",
    "from string import punctuation\n",
    "ratings['ISBN'] = ratings['ISBN'].apply(lambda x: x.translate(str.maketrans('', '', punctuation)).replace(' ', '').upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensuring the special characters have been dealt with\n",
    "ratings['ISBN'] = ratings['ISBN'].apply(correct_isbn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensuring ratings dataset has only books in the merged dataset for books and books extra\n",
    "ratings_new = ratings[ratings.ISBN.isin(book_data.ISBN)]\n",
    "ratings.shape,ratings_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that many rows having book ISBN not part of the merged dataset for books and books extra got dropped off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensuring ratings dataset has only books in the users datset\n",
    "print(\"Shape of dataset before dropping\",ratings_new.shape)\n",
    "ratings_new = ratings_new[ratings_new['User-ID'].isin(users['User-ID'])]\n",
    "print(\"shape of dataset after dropping\",ratings_new.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is evident that no new user was there in the users dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining a function for plotting a countplot\n",
    "def count_plot (column, dataset, heading):\n",
    "    \"\"\"Visualize the countplots of various dataframes with seaborn barplot\n",
    "    \n",
    "    Args: \n",
    "        data: dataframe of various columns and their count returned from count_plot function\n",
    "        \n",
    "    Returns: \n",
    "        countplot: countplot of columns and their count\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15,8));\n",
    "    sns.countplot(y=column, data=dataset, order=pd.value_counts(dataset[column]).iloc[0:15].index);\n",
    "    plt.title(heading);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the distribution of ratings\n",
    "count_plot('Book-Rating', ratings, 'Ratings Distribution')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ratings are unevenly distributed since majority of the ratings are 0. The ratings are either explicit, expressed on a scale of 1-10 with higher values denoting higher appreciation, or implicit, expressed by 0. Hence the need to segragate implicit and explict ratings datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#segregating implicit and explict ratings datasets\n",
    "ratings_explicit = ratings_new[ratings['Book-Rating'] != 0]\n",
    "ratings_implicit = ratings_new[ratings['Book-Rating'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the explicit ratings\n",
    "count_plot('Book-Rating', ratings_explicit, 'Explicit Ratings')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be observed that higher ratings are most common amongst users and rating 8 has been rated the highest number of times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding the top 5 books that are rated most\n",
    "rating_count = pd.DataFrame(ratings_explicit.groupby('ISBN')['Book-Rating'].count())\n",
    "rating_count.sort_values('Book-Rating', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#discovering which book is displayed by the above ISBN numbers\n",
    "most_rated_books = pd.DataFrame(['0316666343', '0971880107', '0385504209', '0312195516', '0060928336'], index=np.arange(5), columns = ['ISBN'])\n",
    "most_rated_books_summary = pd.merge(most_rated_books, book_data, on='ISBN')\n",
    "most_rated_books_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Majority of the books that had a high rating are mainly of category fiction and are all novels. This shows that novels of type fiction are mainly preferred by users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column Rating average consisting the mean of the explicit ratings\n",
    "ratings_explicit['Avg_Rating']=ratings_explicit.groupby('ISBN')['Book-Rating'].transform('mean')\n",
    "# Create column Total-No-Of-Users-Rated consisting the count of explicit ratings \n",
    "ratings_explicit['Total_No_Of_Users_Rated']=ratings_explicit.groupby('ISBN')['Book-Rating'].transform('count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_explicit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging explicit ratings to the users dataset and published2 dataset\n",
    "Final_Dataset=users.copy()\n",
    "Final_Dataset=pd.merge(Final_Dataset,ratings_explicit,on='User-ID')\n",
    "Final_Dataset=pd.merge(Final_Dataset,book_data,on='ISBN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Final_Dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate the 'DescribeData' class for the 'Final_dataset' \n",
    "fd = DescribeData(Final_Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for missing values in the combined dataset to be used for analysis\n",
    "print(fd.missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the count of users per country\n",
    "count_plot('Country', Final_Dataset, 'Count of library users per country')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Majority of library users are based in USA and Canada while Singapore and Italy have the least number of library users."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the most recognised book authors \n",
    "count_plot('authors', Final_Dataset, 'The most recognised Book authors')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The most recognised book authors are Stephen King and John Grisham. On the other hand, Dan Brown and Patricia Dniels Cornwell are the least recognised book authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the most recognised publishers\n",
    "count_plot('Publisher', Final_Dataset, 'The most recognised Publishers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">The most recognised publisher is Ballantine Books and Pocket while the least recognised publisher is Harlequin and Simon &amp Schuster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "eb9a1cfcb3fcd794ed604d243aad9cded6da2afc9012065f3a897ba0af729602"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
